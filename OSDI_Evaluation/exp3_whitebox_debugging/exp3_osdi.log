2025-12-08 00:27:29,655 - __main__ - INFO - ================================================================================
2025-12-08 00:27:29,655 - __main__ - INFO - EXPERIMENT 3: OSDI WHITE-BOX INTERACTIVITY
2025-12-08 00:27:29,655 - __main__ - INFO - ================================================================================
2025-12-08 00:27:29,657 - __main__ - INFO - ‚úÖ Loaded config from ../configs/exp3_osdi_full.yaml
2025-12-08 00:27:29,657 - __main__ - INFO - [Djinn] Initializing client to localhost:5556...
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO - ================================================================================
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO - üöÄ Initializing Djinn Runtime
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO - ================================================================================
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO - [1/5] Loading configuration...
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO -   ‚úì Configuration loaded
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO -   ‚úì Remote server: localhost:5556
2025-12-08 00:27:29,657 - djinn.backend.runtime.initialization - INFO - [2/5] Creating thread pool (size=4)...
2025-12-08 00:27:29,658 - djinn.backend.runtime.initialization - INFO -   ‚úì Thread pool created
2025-12-08 00:27:29,658 - djinn.backend.runtime.initialization - INFO - [3/7] Calling initialization hooks...
2025-12-08 00:27:29,658 - djinn.backend.runtime.initialization - INFO -   ‚úì 0 hooks executed
2025-12-08 00:27:29,659 - djinn.backend.runtime.initialization - INFO - [5/7] Connecting to remote server at localhost:5556...
2025-12-08 00:27:29,661 - djinn.core.coordinator - INFO - Starting DjinnCoordinator: djinn-client
2025-12-08 00:27:29,661 - djinn.core.coordinator - INFO - ‚úì Client coordinator (no control plane server needed)
2025-12-08 00:27:29,663 - djinn.server.transport.tcp_transport - INFO - TCP Transport will listen on port 5561
2025-12-08 00:27:29,663 - djinn.core.coordinator - INFO - ‚úì Result callback registered
2025-12-08 00:27:29,663 - djinn.core.coordinator - INFO - ‚úì TCP fallback available
2025-12-08 00:27:29,663 - djinn.core.coordinator - INFO - ‚úì Operation callback registered
2025-12-08 00:27:29,663 - djinn.core.coordinator - INFO - DjinnCoordinator ready: ['tcp']
2025-12-08 00:27:29,663 - djinn.backend.runtime.initialization - INFO -   ‚úì Connected to remote server
2025-12-08 00:27:29,663 - djinn.backend.runtime.initialization - INFO - [6/7] Warming up GPU on server...
2025-12-08 00:27:30,212 - djinn.backend.runtime.initialization - INFO -   ‚úì GPU already warmed up (shared across clients)
2025-12-08 00:27:30,212 - djinn.backend.runtime.initialization - INFO - [7/7] Querying capabilities...
2025-12-08 00:27:30,213 - djinn.backend.runtime.initialization - WARNING -   ‚úó Failed to query capabilities: Control plane not initialized
2025-12-08 00:27:30,213 - djinn.backend.runtime.initialization - INFO - ================================================================================
2025-12-08 00:27:30,213 - djinn.backend.runtime.initialization - INFO - ‚úÖ Djinn runtime initialized in 555.3ms
2025-12-08 00:27:30,213 - djinn.backend.runtime.initialization - INFO - ================================================================================
2025-12-08 00:27:30,213 - Evaluation.common.djinn_init - INFO - Djinn init succeeded (server=localhost:5556)
2025-12-08 00:27:30,213 - __main__ - INFO - [Djinn] Client initialized
2025-12-08 00:27:30,213 - __main__ - INFO - 
üîµ Running PyTorch Eager baseline...
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - ================================================================================
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - BASELINE: PyTorch Eager - VRAM Holding During Pause
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - ================================================================================
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - Model: gpt2
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - Breakpoint Layer: 6
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - Input Length: 512
2025-12-08 00:27:30,227 - baselines.pytorch_eager_baseline - INFO - Pause Duration: 5s

2025-12-08 00:27:30,262 - baselines.pytorch_eager_baseline - INFO - Initial GPU Memory: {'allocated_gb': 0.0, 'reserved_gb': 0.0, 'total_gb': 79.1788330078125, 'free_gb': 79.1788330078125}
2025-12-08 00:27:30,262 - baselines.pytorch_eager_baseline - INFO - 
Loading model...
2025-12-08 00:27:30,519 - transformers.configuration_utils - WARNING - `torch_dtype` is deprecated! Use `dtype` instead!
2025-12-08 00:27:34,858 - djinn.core.device_compatibility - INFO - Delegating GPT2LMHeadModel.to(cuda:0) to original implementation
2025-12-08 00:27:36,001 - baselines.pytorch_eager_baseline - INFO - Model Loaded. GPU Memory: {'allocated_gb': 0.24461650848388672, 'reserved_gb': 0.462890625, 'total_gb': 79.1788330078125, 'free_gb': 78.93421649932861}
2025-12-08 00:27:36,001 - baselines.pytorch_eager_baseline - INFO - Model Weight VRAM: 0.24GB
2025-12-08 00:27:36,001 - baselines.pytorch_eager_baseline - INFO - 
Preparing input (512 tokens)...
2025-12-08 00:27:36,001 - baselines.pytorch_eager_baseline - ERROR - ‚ùå Baseline failed: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "/home/ubuntu/Djinn/OSDI_Evaluation/exp3_whitebox_debugging/scripts/baselines/pytorch_eager_baseline.py", line 119, in run_pytorch_eager_baseline
    inputs = tokenizer(
             ^^^^^^^^^^
  File "/home/ubuntu/Djinn/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3073, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/Djinn/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3183, in _call_one
    return self.encode_plus(
           ^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/Djinn/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3249, in encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/Djinn/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2969, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-12-08 00:27:36,009 - __main__ - INFO - 
üü¢ Running vLLM API test...
2025-12-08 00:27:36,012 - baselines.vllm_breakpoint_test - INFO - ================================================================================
2025-12-08 00:27:36,012 - baselines.vllm_breakpoint_test - INFO - BASELINE: vLLM API Capability Analysis
2025-12-08 00:27:36,012 - baselines.vllm_breakpoint_test - INFO - ================================================================================
2025-12-08 00:27:36,012 - baselines.vllm_breakpoint_test - INFO - Model: gpt2

2025-12-08 00:27:36,012 - baselines.vllm_breakpoint_test - INFO - Attempting to import vLLM...
2025-12-08 00:27:39,618 - baselines.vllm_breakpoint_test - INFO - ‚úÖ vLLM import successful
2025-12-08 00:27:39,618 - baselines.vllm_breakpoint_test - INFO - 
Initializing vLLM with gpt2...
2025-12-08 00:28:09,809 - baselines.vllm_breakpoint_test - ERROR - ‚ùå Failed to initialize vLLM: Engine core initialization failed. See root cause above. Failed core proc(s): {}
2025-12-08 00:28:09,810 - __main__ - INFO - 
üü° Running Djinn breakpoint tests...
2025-12-08 00:28:09,813 - __main__ - INFO - Loading ghost model gpt2
2025-12-08 00:28:11,371 - djinn.core.coordinator - INFO - Registering model d140314e with remote server...
2025-12-08 00:28:11,372 - djinn.core.coordinator - INFO - ‚úÖ Ghost request serialized in 0.1ms (0.00 MB total)
2025-12-08 00:28:14,276 - djinn.core.coordinator - INFO - ‚úÖ Ghost request sent and response received in 2903.4ms
2025-12-08 00:28:14,276 - djinn.core.coordinator - INFO - ‚úÖ Ghost model d140314e registered on server (total: 2905.0ms)
2025-12-08 00:28:14,276 - djinn.core.enhanced_model_manager - INFO - ‚úÖ Model registered on server: d140314e
2025-12-08 00:28:14,283 - __main__ - INFO - Running baseline Djinn execution (no breakpoint) for accuracy reference
2025-12-08 00:28:14,283 - djinn.core.enhanced_model_manager - WARNING - ‚ö†Ô∏è  Model ddc6980d99882b08 not registered; auto-registering (first run may be slow)...
2025-12-08 00:28:14,283 - djinn.core.coordinator - INFO - Registering model ddc6980d with remote server...
2025-12-08 00:28:14,284 - djinn.core.coordinator - INFO - ‚úÖ Ghost request serialized in 0.0ms (0.00 MB total)
2025-12-08 00:28:15,355 - djinn.core.coordinator - INFO - ‚úÖ Ghost request sent and response received in 1071.7ms
2025-12-08 00:28:15,356 - djinn.core.coordinator - INFO - ‚úÖ Ghost model ddc6980d registered on server (total: 1072.1ms)
2025-12-08 00:28:15,356 - djinn.core.enhanced_model_manager - INFO - ‚úÖ Model registered on server: ddc6980d
2025-12-08 00:28:15,356 - djinn.core.enhanced_model_manager - INFO - ‚úÖ Model ddc6980d auto-registered
2025-12-08 00:28:15,356 - djinn.core.coordinator - INFO - Executing model ddc6980d on remote server...
2025-12-08 00:28:16,064 - djinn.core.coordinator - INFO - ‚úÖ Remote execution successful: 323.29ms
2025-12-08 00:28:16,067 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 3...
2025-12-08 00:28:53,565 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.6ms
   Overhead: 0.3%
2025-12-08 00:28:53,616 - __main__ - INFO - Djinn trial 1/3, layer 3: token_accuracy=100.00%
2025-12-08 00:28:53,616 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 6...
2025-12-08 00:28:54,330 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.7ms
   Overhead: 66.2%
2025-12-08 00:28:54,372 - __main__ - INFO - Djinn trial 1/3, layer 6: token_accuracy=100.00%
2025-12-08 00:28:54,373 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 9...
2025-12-08 00:28:55,087 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.7ms
   Overhead: 70.0%
2025-12-08 00:28:55,131 - __main__ - INFO - Djinn trial 1/3, layer 9: token_accuracy=100.00%
2025-12-08 00:28:55,131 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 3...
2025-12-08 00:28:55,836 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.7ms
   Overhead: 75.4%
2025-12-08 00:28:55,877 - __main__ - INFO - Djinn trial 2/3, layer 3: token_accuracy=100.00%
2025-12-08 00:28:55,878 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 6...
2025-12-08 00:28:56,395 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 0.9ms
   Overhead: 80.3%
2025-12-08 00:28:56,434 - __main__ - INFO - Djinn trial 2/3, layer 6: token_accuracy=100.00%
2025-12-08 00:28:56,434 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 9...
2025-12-08 00:28:56,942 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.2ms
   Overhead: 83.5%
2025-12-08 00:28:56,980 - __main__ - INFO - Djinn trial 2/3, layer 9: token_accuracy=100.00%
2025-12-08 00:28:56,980 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 3...
2025-12-08 00:28:57,493 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.0ms
   Overhead: 81.9%
2025-12-08 00:28:57,530 - __main__ - INFO - Djinn trial 3/3, layer 3: token_accuracy=100.00%
2025-12-08 00:28:57,530 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 6...
2025-12-08 00:28:58,037 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 0.9ms
   Overhead: 82.5%
2025-12-08 00:28:58,074 - __main__ - INFO - Djinn trial 3/3, layer 6: token_accuracy=100.00%
2025-12-08 00:28:58,074 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 9...
2025-12-08 00:28:58,586 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 1.1ms
   Overhead: 84.0%
2025-12-08 00:28:58,624 - __main__ - INFO - Djinn trial 3/3, layer 9: token_accuracy=100.00%
2025-12-08 00:28:58,625 - __main__ - INFO - 
üìä BREAKPOINT TRIAL SUMMARY:
  Token Accuracy: 100.00% (¬±0.00%)
  Latency: 4691.5ms (¬±11601.1ms)
  OS Overhead: 0.2% (max 0.2%)
2025-12-08 00:28:58,628 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 6...
2025-12-08 00:28:58,649 - djinn.core.coordinator - INFO - ‚úÖ Extracted checkpoint_activation for steering (shape=torch.Size([1, 512, 768]))
2025-12-08 00:28:58,650 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 0.0ms
   Overhead: 0.0%
2025-12-08 00:28:58,650 - djinn.core.coordinator - INFO - Resuming from checkpoint for session session_2ccce153627f (layer=6, activation_shape=torch.Size([1, 512, 768]))
2025-12-08 00:28:59,047 - djinn.core.coordinator - INFO - ‚úÖ Resume from checkpoint successful for session session_2ccce153627f
2025-12-08 00:28:59,050 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 6...
2025-12-08 00:28:59,064 - djinn.core.coordinator - INFO - ‚úÖ Extracted checkpoint_activation for steering (shape=torch.Size([1, 512, 768]))
2025-12-08 00:28:59,064 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 0.0ms
   Overhead: 0.0%
2025-12-08 00:28:59,066 - djinn.core.coordinator - INFO - Resuming from checkpoint for session session_95e4f0e3eb3e (layer=6, activation_shape=torch.Size([1, 512, 768]))
2025-12-08 00:28:59,456 - djinn.core.coordinator - INFO - ‚úÖ Resume from checkpoint successful for session session_95e4f0e3eb3e
2025-12-08 00:28:59,492 - __main__ - INFO - 
‚úÖ ACTIVATION STEERING DEMO:
  Layer: 6, Scale: 0.90
  Output Changed: True
  Token Diff: 0.39%
  Resume Latency (baseline): 0.8ms
  Resume Latency (steered): 0.7ms
2025-12-08 00:28:59,498 - djinn.core.coordinator - INFO - Executing model d140314e on remote server with breakpoint at layer 6...
2025-12-08 00:28:59,512 - djinn.core.coordinator - INFO - ‚úÖ Extracted checkpoint_activation for steering (shape=torch.Size([1, 512, 768]))
2025-12-08 00:28:59,512 - djinn.core.coordinator - INFO - ‚úÖ Breakpoint execution successful:
   Checkpoint: 0.0ms
   Restore: 0.0ms
   Overhead: 0.0%
2025-12-08 00:28:59,512 - __main__ - INFO - Concurrent demo: VRAM before Request B: 41.32 GB
2025-12-08 00:28:59,512 - djinn.core.coordinator - INFO - Executing model ddc6980d on remote server...
2025-12-08 00:28:59,883 - djinn.core.coordinator - INFO - ‚úÖ Remote execution successful: 19.16ms
2025-12-08 00:28:59,887 - __main__ - INFO - Concurrent demo: VRAM during pause: 41.46 GB
2025-12-08 00:28:59,887 - djinn.core.coordinator - INFO - Resuming from checkpoint for session session_8b18d4e3e3d0 (layer=6, activation_shape=torch.Size([1, 512, 768]))
2025-12-08 00:29:00,290 - djinn.core.coordinator - INFO - ‚úÖ Resume from checkpoint successful for session session_8b18d4e3e3d0
2025-12-08 00:29:00,316 - __main__ - INFO - Djinn breakpoint results saved to /tmp/exp3_h100_results/djinn_breakpoint_results.json
2025-12-08 00:29:00,328 - __main__ - INFO - 
üìä COMPARATIVE RESULTS TABLE:

2025-12-08 00:29:00,328 - __main__ - INFO - Metric                         PyTorch Eager             vLLM                      Djinn                    
2025-12-08 00:29:00,329 - __main__ - INFO - --------------------------------------------------------------------------------------------------------------
2025-12-08 00:29:00,329 - __main__ - INFO - breakpoint_support             Manual (holds VRAM)       NOT POSSIBLE              Native pause/resume      
2025-12-08 00:29:00,329 - __main__ - INFO - vram_during_pause_gb           N/A                       N/A                       41.46 GB                 
2025-12-08 00:29:00,329 - __main__ - INFO - concurrent_requests            NO                        NO                        YES                      
2025-12-08 00:29:00,329 - __main__ - INFO - activation_steering            Manual, blocks GPU        NOT POSSIBLE              Steering demo completed  
2025-12-08 00:29:00,329 - __main__ - INFO - token_accuracy_percent         100 (reference)           N/A                       100.00                   
2025-12-08 00:29:00,329 - __main__ - INFO - Comparative report saved to /tmp/exp3_h100_results/comparative_results.json
2025-12-08 00:29:00,329 - __main__ - INFO - 
‚úÖ EXPERIMENT 3 EVALUATION COMPLETE
2025-12-08 00:29:00,329 - __main__ - INFO - Results saved to /tmp/exp3_h100_results
