experiment:
  name: "semantic_scheduler_agent_scaling_smoke"
  description: "Quick validation of semantic scheduler (1-4 agents, 2s sleep)"
  version: "1.0"

workload:
  model_id: "meta-llama/Llama-2-7b-hf"
  dtype: "float16"
  agent_counts: [1, 2, 4]
  new_tokens: 50
  sleep_seconds: 2.0
  iterations: 1

semantic_scheduler:
  enabled: true
  idle_threshold_seconds: 1.0
  host_swap_pool_gb: 16.0
  lifo_on_overload: true

server_config:
  enable_semantic_scheduler: true
  idle_threshold_seconds: 1.0
  host_swap_pool_gb: 16.0
  max_concurrent: 32

expected_results:
  agents_1:
    p99_latency_ms: 120
    success: true
  agents_2:
    p99_latency_ms: 130
    success: true
  agents_4:
    p99_latency_ms: 140
    success: true

